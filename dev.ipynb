{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "class OpenAIAssistant:\n",
    "    def __init__(self, api_key, assistant_id):\n",
    "        self.api_key = api_key\n",
    "        self.assistant_id = assistant_id\n",
    "        self.headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "            \"OpenAI-Beta\": \"assistants=v2\",\n",
    "        }\n",
    "\n",
    "    def create_thread(self):\n",
    "        response = requests.post(\"https://api.openai.com/v1/threads\", headers=self.headers, json={})\n",
    "        response.raise_for_status()  # Ensure request was successful\n",
    "        return response.json()['id']\n",
    "\n",
    "    def send_message(self, thread_id, message_content):\n",
    "        url = f\"https://api.openai.com/v1/threads/{thread_id}/messages\"\n",
    "        payload = {\"role\": \"user\", \"content\": message_content}\n",
    "        response = requests.post(url, headers=self.headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "\n",
    "    def start_run(self, thread_id):\n",
    "        url = f\"https://api.openai.com/v1/threads/{thread_id}/runs\"\n",
    "        payload = {\"assistant_id\": self.assistant_id}\n",
    "        response = requests.post(url, headers=self.headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.json()['id']\n",
    "\n",
    "    def poll_run_status_and_get_response(self, thread_id, run_id):\n",
    "        url = f\"https://api.openai.com/v1/threads/{thread_id}/runs/{run_id}\"\n",
    "        while True:\n",
    "            response = requests.get(url, headers=self.headers)\n",
    "            response.raise_for_status()  # Ensure request was successful\n",
    "            run_data = response.json()\n",
    "            status = run_data['status']\n",
    "            print(f\"Checking run status: {status}\")  # Debugging output\n",
    "\n",
    "            if status == 'completed':\n",
    "                print(\"Run completed successfully. Fetching messages...\")\n",
    "                return self.fetch_messages(thread_id)\n",
    "            elif status in ['failed', 'cancelled', 'expired']:\n",
    "                raise Exception(f\"Run did not complete successfully: {status}\")\n",
    "            else:\n",
    "                time.sleep(0.1)  # Wait for a few seconds before retrying\n",
    "\n",
    "    def fetch_messages(self, thread_id):\n",
    "        url = f\"https://api.openai.com/v1/threads/{thread_id}/messages\"\n",
    "        response = requests.get(url, headers=self.headers)\n",
    "        response.raise_for_status()  # Ensure request was successful\n",
    "        messages_data = response.json()\n",
    "        print(\"Messages fetched successfully.\")\n",
    "        return messages_data['data']\n",
    "\n",
    "    def process_message(self, thread_id, prompt_message):\n",
    "        self.send_message(thread_id, prompt_message)\n",
    "        run_id = self.start_run(thread_id)\n",
    "        messages = self.poll_run_status_and_get_response(thread_id, run_id)\n",
    "        if messages and messages[0]['role'] == 'assistant':\n",
    "            content = messages[0]['content'][0]['text']['value']\n",
    "            json_string = content.replace('```json\\n', '').replace('\\n```', '')\n",
    "            extracted_json = json.loads(json_string)\n",
    "            return extracted_json\n",
    "        else:\n",
    "            print(\"No assistant message found or the first message is not from the assistant.\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import requests\n",
    "\n",
    "def retrieve_api_key():\n",
    "    \"\"\"Retrieve the API key from environment variables.\"\"\"\n",
    "    api_key = os.getenv('OPENAI_API_KEY')\n",
    "    if api_key is None:\n",
    "        raise ValueError(\"API key not found in environment variables\")\n",
    "    return api_key\n",
    "\n",
    "class GPTManager:\n",
    "    def __init__(self):\n",
    "        self.api_key = retrieve_api_key()\n",
    "\n",
    "    def encode_image(self, image_path):\n",
    "        \"\"\"Encode the image at the given path to Base64.\"\"\"\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    def send_request(self, image_path):\n",
    "        \"\"\"Send a request to the OpenAI API with the encoded image and extract specific response.\"\"\"\n",
    "        base64_image = self.encode_image(image_path)\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\"\n",
    "        }\n",
    "\n",
    "        prompt = \"\"\"\n",
    "            As a sysadmin bot, your task is to analyze a macOS terminal screenshot and extract relevant text, organizing it into a structured JSON format. Focus on the following components:\n",
    "            {\n",
    "                \"highlighted\": \"All highlighted text in the terminal\",\n",
    "                \"history\": [\n",
    "                    {\n",
    "                        \"command\": \"The executed command\",\n",
    "                        \"output\": \"Output from the command\"\n",
    "                    }\n",
    "                ],\n",
    "                \"messagesToAssistant\": {\n",
    "                    \"sbMessages\": \"Commands starting with 'sb' directed to the assistant\"\n",
    "                },\n",
    "                \"mostRecent\": {\n",
    "                    \"item\": \"Most recent item, which could be a command, error message, or 'sb' message\"\n",
    "                }\n",
    "            }\n",
    "            Extraction Rules:\n",
    "            - Exclude any user and PC names from the output.\n",
    "            - Separate commands and their outputs in the history.\n",
    "            - Include only text that starts with 'sb' in the 'messagesToAssistant'.\n",
    "            - Identify and log only the single most recent item (command, error, or 'sb' message) under 'mostRecent'.\n",
    "            Ensure strict adherence to the JSON structure for compatibility with further processing.\n",
    "        \"\"\"\n",
    "        payload = {\n",
    "            \"model\": \"gpt-4o\",  # Ensure to use a valid model identifier\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 1000  # Adjusted max_tokens for possibly longer responses needed by the detailed prompt\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "            response.raise_for_status()  # Raises an HTTPError for bad responses\n",
    "            # Extracting only the message content from the response\n",
    "            content = response.json()['choices'][0]['message']['content']\n",
    "            print('\\nThis is the content of the response:')#, response.json(), '\\n')\n",
    "            from pprint import pprint\n",
    "            pprint(response.json())\n",
    "            \n",
    "            json_string = content.replace('```json\\n', '').replace('\\n```', '')\n",
    "            extracted_json = json.loads(json_string)\n",
    "            return extracted_json\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def list_sorted_images(directory):\n",
    "    \"\"\"List image files in a directory sorted numerically by filename.\"\"\"\n",
    "    # List all files in the directory\n",
    "    files = os.listdir(directory)\n",
    "    # Filter out only files that end with '.png'\n",
    "    images = [file for file in files if file.endswith('.png')]\n",
    "    # Sort files numerically by extracting the integer from filenames assuming format 'number.png'\n",
    "    images_sorted = sorted(images, key=lambda x: int(x.split('.')[0]))\n",
    "    return images_sorted\n",
    "\n",
    "# Usage example\n",
    "#directory_path = 'terminal_content/flow_1/images/'\n",
    "directory_path = 'terminal_content/flow_2/images/'\n",
    "sorted_images = list_sorted_images(directory_path)\n",
    "img_paths = [os.path.join(directory_path, img) for img in sorted_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is the content of the response:\n",
      "{'choices': [{'finish_reason': 'stop',\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'content': '{\\n'\n",
      "                                     '    \"highlighted\": \"\",\\n'\n",
      "                                     '    \"history\": [],\\n'\n",
      "                                     '    \"messagesToAssistant\": {\\n'\n",
      "                                     '        \"sbMessages\": \"\"\\n'\n",
      "                                     '    },\\n'\n",
      "                                     '    \"mostRecent\": {\\n'\n",
      "                                     '        \"item\": \"\"\\n'\n",
      "                                     '    }\\n'\n",
      "                                     '}',\n",
      "                          'role': 'assistant'}}],\n",
      " 'created': 1717854317,\n",
      " 'id': 'chatcmpl-9Xqfdn1UMrTKJ2lM6s4FLms0LU4xH',\n",
      " 'model': 'gpt-4o-2024-05-13',\n",
      " 'object': 'chat.completion',\n",
      " 'system_fingerprint': 'fp_aa87380ac5',\n",
      " 'usage': {'completion_tokens': 41,\n",
      "           'prompt_tokens': 1002,\n",
      "           'total_tokens': 1043}}\n"
     ]
    }
   ],
   "source": [
    "# Usage Example\n",
    "api_key = retrieve_api_key()\n",
    "assistant_id = \"asst_IQyOH1i0Qjs0agZsBE23nQrS\"\n",
    "assistant = OpenAIAssistant(api_key, assistant_id)\n",
    "thread_id = assistant.create_thread()  # Create thread outside the process message\n",
    "\n",
    "# Usage\n",
    "gpt_manager = GPTManager()\n",
    "\n",
    "results = []\n",
    "cc = 0\n",
    "for img_path in img_paths:\n",
    "    dict_img_text_content = gpt_manager.send_request(img_path)\n",
    "    #dict_assistant_response = assistant.process_message(thread_id, prompt_message=json.dumps(dict_img_text_content))\n",
    "\n",
    "    #result = {\n",
    "    #    'img_path': img_path,\n",
    "    #    'dict_img_text_content': dict_img_text_content,\n",
    "    #    'dict_model_response': dict_assistant_response\n",
    "    #}\n",
    "    #results.append(result)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking run status: in_progress\n",
      "Checking run status: completed\n",
      "Run completed successfully. Fetching messages...\n",
      "Messages fetched successfully.\n",
      "Response from GPT:\n",
      "\n",
      "{'intention': 'create and run a Python script with pandas', 'command': 'python3 script.py'}\n"
     ]
    }
   ],
   "source": [
    "assistant_id = \"asst_IQyOH1i0Qjs0agZsBE23nQrS\"\n",
    "assistant = OpenAIAssistant(api_key, assistant_id)\n",
    "thread_id = assistant.create_thread()  # Create thread outside the process message\n",
    "dict_assistant_response = assistant.process_message(thread_id, prompt_message=json.dumps(dict_img_text_content))\n",
    "print('Response from GPT:\\n')\n",
    "print(dict_assistant_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intention': 'run the created Python script', 'command': 'python script.py'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]['dict_model_response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_markdown_report(results, flow_number):\n",
    "    md_content = \"# Image Processing Report\\n\\n\"\n",
    "    for result in results:\n",
    "        relative_img_path = f\"../{result['img_path']}\"  # Adjusting path to be relative to the Markdown file location\n",
    "        md_content += f\"## Image: {os.path.basename(result['img_path'])}\\n\\n\"\n",
    "        md_content += f\"![Image]({relative_img_path})\\n\\n\"\n",
    "        # Formatting the extracted text content as JSON with syntax highlighting\n",
    "        md_content += f\"**Extracted Text:**\\n\\n```json\\n{json.dumps(result['dict_img_text_content'], indent=4)}\\n```\\n\\n\"\n",
    "        # Formatting the AI response as JSON with syntax highlighting\n",
    "        md_content += f\"**AI Response:**\\n\\n```json\\n{json.dumps(result['dict_model_response'], indent=4)}\\n```\\n\\n\"\n",
    "\n",
    "    report_dir = './reports'\n",
    "    os.makedirs(report_dir, exist_ok=True)\n",
    "    with open(f\"{report_dir}/flow_{flow_number}.md\", 'w') as file:\n",
    "        file.write(md_content)\n",
    "\n",
    "# Example usage, assuming results and flow_number have been defined and set appropriately\n",
    "generate_markdown_report(results, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
